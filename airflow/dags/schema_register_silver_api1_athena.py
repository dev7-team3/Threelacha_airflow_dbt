import logging

from connection_utils import get_athena_config, get_query_engine_conn_id
import pendulum

from airflow.providers.amazon.aws.operators.athena import AthenaOperator
from airflow.sdk import dag, task

logger = logging.getLogger("airflow.task")


@dag(
    dag_id="schema_register_silver_api1_athena",
    start_date=pendulum.datetime(2025, 1, 1, tz="UTC"),
    schedule=None,
    catchup=False,
    default_args={
        "owner": "jungeun_park",
        "retries": 0,
    },
    tags=["KAMIS", "api-1", "silver", "athena", "schema"],
    description="Silver API1 í…Œì´ë¸”ì„ Athena(Glue)ì— ë“±ë¡ ë° íŒŒí‹°ì…˜ ë™ê¸°í™”",
)
def register_silver_api1_athena():
    """
    Athenaìš© Silver API1 í…Œì´ë¸” ë“±ë¡ í”„ë¡œì„¸ìŠ¤
    ì²˜ë¦¬ íë¦„:
    1. team3_silver ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    2. api1 í…Œì´ë¸” ìƒì„± ë° íŒŒí‹°ì…˜ ë™ê¸°í™”
    3. team3_gold ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (dbt ì‚¬ìš©ì„ ìœ„í•´)
    """

    conn_id = get_query_engine_conn_id()
    _, workgroup = get_athena_config(conn_id)

    @task
    def log_start():
        """ì‹œìž‘ ë¡œê¹…"""
        logger.info("=" * 80)
        logger.info("ðŸ”§ Athena ìŠ¤í‚¤ë§ˆ ë“±ë¡ ì‹œìž‘")
        logger.info(f"   - Connection: {conn_id}")
        logger.info(f"   - WorkGroup: {workgroup}")
        logger.info("=" * 80)

    start_log = log_start()

    # 1. Silver ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    create_silver_schema = AthenaOperator(
        task_id="create_silver_schema",
        aws_conn_id=conn_id,
        query="CREATE DATABASE IF NOT EXISTS team3_silver COMMENT 'Silver layer for team3'",
        database="default",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    # 2. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
    drop_existing_table = AthenaOperator(
        task_id="drop_existing_table",
        aws_conn_id=conn_id,
        query="DROP TABLE IF EXISTS team3_silver.api1",
        database="team3_silver",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    # 3. Silver API1 í…Œì´ë¸” ìƒì„±
    create_api1_table = AthenaOperator(
        task_id="create_api1_table",
        aws_conn_id=conn_id,
        query="""
        CREATE EXTERNAL TABLE IF NOT EXISTS team3_silver.api1 (
            res_dt DATE,
            week_of_year INT,
            weekday_num INT,
            weekday_nm STRING,
            weekend_yn BOOLEAN,
            product_cls_cd STRING,
            product_cls_nm STRING,
            category_cd STRING,
            category_nm STRING,
            country_cd STRING,
            country_nm STRING,
            item_nm STRING,
            item_cd STRING,
            kind_nm STRING,
            kind_cd STRING,
            rank_nm STRING,
            rank_cd STRING,
            unit STRING,
            base_dt STRING,
            base_pr DOUBLE,
            prev_1d_dt STRING,
            prev_1d_pr DOUBLE,
            prev_1w_dt STRING,
            prev_1w_pr DOUBLE,
            prev_2w_dt STRING,
            prev_2w_pr DOUBLE,
            prev_1m_dt STRING,
            prev_1m_pr DOUBLE,
            prev_1y_dt STRING,
            prev_1y_pr DOUBLE,
            avg_tp STRING,
            avg_pr DOUBLE
        )
        COMMENT 'KAMIS API1 Silver ë ˆì´ì–´'
        PARTITIONED BY (year STRING, month STRING)
        STORED AS PARQUET
        LOCATION 's3://team3-batch/silver/api-1/'
        TBLPROPERTIES ('parquet.compress'='SNAPPY')
        """,
        database="team3_silver",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    # 4. íŒŒí‹°ì…˜ ë™ê¸°í™”
    sync_partitions = AthenaOperator(
        task_id="sync_partitions",
        aws_conn_id=conn_id,
        query="MSCK REPAIR TABLE team3_silver.api1",
        database="team3_silver",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    # 5. í…Œì´ë¸” ê²€ì¦
    verify_table = AthenaOperator(
        task_id="verify_table",
        aws_conn_id=conn_id,
        query="SELECT COUNT(*) as total_count, COUNT(DISTINCT year) as year_count, COUNT(DISTINCT month) as month_count FROM api1",
        database="team3_silver",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    # 6. Gold ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (dbt ì‚¬ìš©ì„ ìœ„í•´)
    create_gold_schema = AthenaOperator(
        task_id="create_gold_schema",
        aws_conn_id=conn_id,
        query="CREATE DATABASE IF NOT EXISTS team3_gold COMMENT 'Gold layer for team3' LOCATION 's3://team3-batch/gold/'",
        database="default",
        workgroup=workgroup,
        output_location="s3://team3-batch/gold/athena-results/",
    )

    @task
    def log_completion():
        """ì™„ë£Œ ë¡œê¹…"""
        logger.info("=" * 80)
        logger.info("âœ… Athena ìŠ¤í‚¤ë§ˆ ë“±ë¡ ì™„ë£Œ!")
        logger.info("=" * 80)
        logger.info("ðŸ“‹ ìƒì„±ëœ ë¦¬ì†ŒìŠ¤:")
        logger.info("   - Database: team3_silver")
        logger.info("     - Table: api1")
        logger.info("     - Location: s3://team3-batch/silver/api-1/")
        logger.info("   - Database: team3_gold")
        logger.info("     - Location: s3://team3-batch/gold/")
        logger.info("=" * 80)
        logger.info("ðŸŽ¯ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info("   1. Athena ì½˜ì†”ì—ì„œ í…Œì´ë¸” í™•ì¸")
        logger.info("   2. dbt ëª¨ë¸ ê°œë°œ ë° ì‹¤í–‰")
        logger.info("=" * 80)

    completion_log = log_completion()

    # Task ì˜ì¡´ì„± ì„¤ì •
    (
        start_log
        >> create_silver_schema
        >> drop_existing_table
        >> create_api1_table
        >> sync_partitions
        >> verify_table
        >> create_gold_schema
        >> completion_log
    )


register_silver_api1_athena()
