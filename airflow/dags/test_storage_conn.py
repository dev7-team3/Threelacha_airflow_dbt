import logging
import os
from typing import Any, Dict

from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.sdk import dag, task
from connection_utils import get_storage_conn_id
import pendulum


@dag(
    dag_id="test_storage_conn",
    schedule=None,
    start_date=pendulum.datetime(2025, 1, 1),
    catchup=False,
    default_args={
        "owner": "jungeun_park",
        "retries": 1,  # ì¬ì‹œë„ ì„¤ì • ì¶”ê°€
    },
    tags=["test", "storage", "connection"],
    description="Airflow êµ¬ë™ í™˜ê²½ì— ì í•©í•œ Storage ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ DAG",
)
def simple_storage_conn_test():
    """
    Airflowì˜ S3Hookì„ ì‚¬ìš©í•˜ì—¬ Storage ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•˜ê³ ,
    ë²„í‚· ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” DAG
    """

    @task
    def test_storage_connection() -> Dict[str, Any]:
        """Storage ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ë²„í‚· ëª©ë¡ ì¡°íšŒ"""
        logger = logging.getLogger(__name__)
        # ëŸ°íƒ€ì„ì— conn_id ê²°ì •
        conn_id = get_storage_conn_id()
        env = os.environ.get("AIRFLOW_ENV", "local")

        try:
            # S3Hook ì´ˆê¸°í™”
            hook = S3Hook(aws_conn_id=conn_id)
            # Boto3 í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            client = hook.get_conn()
            # ë²„í‚· ëª©ë¡ ì¡°íšŒ
            buckets_response = client.list_buckets()
            logger.info("=" * 50)
            logger.info("âœ… ì—°ê²° ì„±ê³µ! ë²„í‚· ëª©ë¡ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.")
            logger.info("=" * 50)
            # ë²„í‚· ì •ë³´ ì¶”ì¶œ
            buckets = buckets_response.get("Buckets", [])
            bucket_names = [b["Name"] for b in buckets]
            logger.info(f"í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë²„í‚· ìˆ˜: {len(bucket_names)}")
            for idx, name in enumerate(bucket_names, 1):
                logger.info(f"  {idx}. {name}")
            # ê²°ê³¼ ë°˜í™˜ (ë‹¤ë¥¸ íƒœìŠ¤í¬ì—ì„œ í™œìš© ê°€ëŠ¥)
            return {
                "status": "success",
                "environment": env,
                "connection_id": conn_id,
                "bucket_count": len(bucket_names),
                "buckets": bucket_names,
            }
        except Exception as e:
            logger.exception("=" * 50)
            logger.exception("âŒ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” API í˜¸ì¶œ ì˜¤ë¥˜ ë°œìƒ")
            logger.exception(f"   - Connection ID: {conn_id}")
            logger.exception(f"   - ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            logger.exception(f"   - ì—ëŸ¬ ë©”ì‹œì§€: {e!s}")  # noqa: TRY401
            logger.exception("=" * 50)
            logger.exception("ğŸ”§ í™•ì¸ ì‚¬í•­:")
            logger.exception(f"   1. Airflow UIì—ì„œ '{conn_id}' ì—°ê²°ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            logger.exception("   2. Storage ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            logger.exception("   3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸")
            raise

    test_storage_connection()


simple_storage_conn_test()
