from datetime import datetime, timedelta
import logging

from airflow.decorators import dag, task
from api_caller_utils import call_kamis_api, validate_api17_response
from connection_utils import get_storage_conn_id
from metadata_loader_utils import MetadataLoader, generate_api17_params
from s3_uploader_utils import build_s3_path, upload_json_to_s3

logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
S3_CONN_ID = get_storage_conn_id()
API17_ACTION = "periodRetailProductList"

# ì½”ë“œ ë§¤í•‘ ë°ì´í„° ë¡œë“œ
country_code_mapping = MetadataLoader.get_country_codes(wholesale_only=True)


def group_data_by_date(data: dict) -> dict[str, list] | None:
    """
    ë‚ ì§œë³„ë¡œ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.

    Args:
        data: API ì‘ë‹µ ë°ì´í„°

    Returns:
        ë‚ ì§œë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬. ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    """
    grouped = {}

    # API ì‘ë‹µ ê²€ì¦
    validate_api17_response(data)

    items = data.get("data", {}).get("item", [])
    if not isinstance(items, list):
        items = [items] if items else []

    for item in items:
        yyyy = item.get("yyyy", "")
        regday = item.get("regday", "")

        if yyyy and regday:
            # "12/17" -> "12-17" (MM/DD -> MM-DD)
            month_day = regday.replace("/", "-")
            date_str = f"{yyyy}-{month_day}"  # "2025-12-17"

            if date_str not in grouped:
                grouped[date_str] = []
            grouped[date_str].append(item)

    if not grouped:
        return None

    return grouped


def get_data(
    country_code: str,
    item_category_code: str,
    item_code: str,
    kind_code: str,
    product_rank_code: str,
    start_day: str,
    end_day: str,
) -> dict | None:
    """
    APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Args:
        country_code: ë„ì‹œ ì½”ë“œ
        item_category_code: ì¹´í…Œê³ ë¦¬ ì½”ë“œ
        item_code: í’ˆëª© ì½”ë“œ
        kind_code: í’ˆì¢… ì½”ë“œ
        product_rank_code: íŒë§¤ì½”ë“œ
        start_day: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_day: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)

    Returns:
        ë‚ ì§œë³„ ë°ì´í„°. ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    """
    params = {
        "p_startday": start_day,
        "p_endday": end_day,
        "p_countrycode": country_code,
        "p_convert_kg_yn": "N",
        "p_itemcategorycode": item_category_code,
        "p_itemcode": item_code,
        "p_kindcode": kind_code,
        "p_productrankcode": product_rank_code,
    }

    logger.info(f"ğŸ”„ Getting data for country={country_code}, category={item_category_code}")

    try:
        response = call_kamis_api(action=API17_ACTION, params=params, timeout=30)

        logger.info(response)
        return group_data_by_date(response)
    except Exception as e:
        logger.warning(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def upload_data_to_s3(
    country_code: str,
    date_data: dict[str, list],
    category_info: dict,
) -> None:
    """
    ë‚ ì§œë³„ ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        country_code: ë„ì‹œ ì½”ë“œ
        date_data: ë‚ ì§œë³„ ë°ì´í„°
        category_info: ì¹´í…Œê³ ë¦¬, í’ˆëª©, í’ˆì¢…, íŒë§¤ì½”ë“œ ì •ë³´
    """
    product_cls = "01"
    item_category_code = category_info["item_category_code"]
    item_code = category_info["item_code"]
    kind_code = category_info["kind_code"]
    product_rank_code = category_info["product_rank_code"]

    for date_str, data in date_data.items():
        key = build_s3_path(
            api_number="17",
            dt=date_str,
            product_cls=product_cls,
            country=country_code,
            category=item_category_code,
            item=item_code,
            kind=kind_code,
            product_rank=product_rank_code,
        )

        upload_json_to_s3(data=data, s3_key=key)


@dag(
    dag_id="raw_api17_collect_daily",
    start_date=datetime(2025, 12, 10),
    schedule="0 5 * * *",  # ë§¤ì¼ ì˜¤ì „ 5ì‹œ
    catchup=False,
    max_active_runs=1,
    default_args={
        "depends_on_past": False,
        "owner": "jiyeon_kim",
        "retries": 3,
        "retry_delay": timedelta(minutes=5),
    },
    tags=["ingestion", "api17"],
    description="KAMIS API17 ì†Œë§¤ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ DAG",
)
def raw_api17_collect_daily():
    """
    KAMIS API17 Raw ë°ì´í„° ìˆ˜ì§‘ DAG

    ê° ì§€ì—­ë³„ë¡œ ë³‘ë ¬ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ S3 Raw ë ˆì´ì–´ì— ì €ì¥í•©ë‹ˆë‹¤.
    TaskFlow APIì˜ expand ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ taskë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        None
    """

    @task
    def collect_data_by_country(country_code: str, **context) -> None:
        """
        íŠ¹ì • ì§€ì—­ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

        Args:
            country_code: ë„ì‹œ ì½”ë“œ
            **context: Airflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            None
        """
        # date_infoë¥¼ contextì—ì„œ ê°€ì ¸ì˜¤ê¸°
        logical_date = context.get("logical_date") or context.get("data_interval_start")
        if logical_date is None:
            raise ValueError("logical_date ë˜ëŠ” data_interval_startë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        start_day = (logical_date - timedelta(days=1)).strftime("%Y-%m-%d")
        end_day = logical_date.strftime("%Y-%m-%d")

        for category in generate_api17_params():
            data_from_api = get_data(
                country_code=country_code,
                item_category_code=category["item_category_code"],
                item_code=category["item_code"],
                kind_code=category["kind_code"],
                product_rank_code=category["product_rank_code"],
                start_day=start_day,
                end_day=end_day,
            )

            if data_from_api is None:
                logger.warning(
                    f"âŒ No data found for {country_code} {start_day}~{end_day} "
                    f"{category['item_category_code']}/{category['item_code']}/"
                    f"{category['kind_code']}/{category['product_rank_code']}"
                )
                continue

            upload_data_to_s3(
                country_code=country_code,
                date_data=data_from_api,
                category_info=category,
            )

        logger.info(f"âœ… Completed data collection for country: {country_code}")

    # DAG ì‹¤í–‰ íë¦„
    # ê° ì§€ì—­ë³„ë¡œ ë³‘ë ¬ task ìƒì„± (date_infoëŠ” contextì—ì„œ ê°€ì ¸ì˜´)
    country_codes = list(country_code_mapping.keys())
    logger.info(f"ì§€ì—­ ì½”ë“œ ëª©ë¡: {country_codes} (ì´ {len(country_codes)}ê°œ)")
    collect_data_by_country.expand(country_code=country_codes)


# DAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
raw_api17_collect_daily()
