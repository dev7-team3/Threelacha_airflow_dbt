# ============================================================
# Imports
# ============================================================

import json
import logging
import os
from pathlib import Path
import time
from typing import Any

import boto3
from dotenv import load_dotenv
import requests

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# logging ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Config
base_url = os.environ["KAMIS_BASE_URL"]

common_params = {
    "action": "EcoPriceList",
    "p_cert_key": os.environ["CERT_KEY"],
    "p_cert_id": os.environ["CERT_ID"],
    "p_returntype": "json",
    "p_product_cls_code": "01",
    "p_convert_kg_yn": "N",
}

# ============================================================
# 1. S3 JSON ì—…ë¡œë“œ í•¨ìˆ˜
# ============================================================


def upload_json_to_s3(
    data: dict[str, Any],
    bucket: str,
    key: str,
) -> None:
    """
    JSON ê°ì²´ë¥¼ S3ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    ê¸°ì¡´ objectê°€ ìˆìœ¼ë©´ overwrite ë°œìƒ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        data (dict): JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬
        bucket (str): ëŒ€ìƒ ë²„í‚· ì´ë¦„
        key (str): S3 ì˜¤ë¸Œì íŠ¸ í‚¤

    Returns:
        bool: Trueë©´ overwrite, Falseë©´ ì‹ ê·œ ì ì¬
    """
    client = boto3.client("s3")

    body = json.dumps(
        data,
        ensure_ascii=False,
        separators=(",", ":"),
    )

    # ê¸°ì¡´ object ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    try:
        client.head_object(Bucket=bucket, Key=key)
        existed = True  # ì´ë¯¸ ì¡´ì¬ â†’ overwrite
    except client.exceptions.ClientError:
        existed = False  # ì¡´ì¬í•˜ì§€ ì•ŠìŒ â†’ ì‹ ê·œ ì ì¬

    client.put_object(
        Bucket=bucket,
        Key=key,
        Body=body.encode("utf-8"),
        ContentType="application/json",
    )

    return existed


# ============================================================
# 2. S3 object key ìƒì„± í•¨ìˆ˜
# ============================================================


def build_s3_object_key(
    response_json: dict[str, Any],
    *,
    base_prefix: str = "raw/api-13",
) -> str:
    """
    API ì‘ë‹µ ì¡°ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ S3 ì˜¤ë¸Œì íŠ¸ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ë””ë ‰í† ë¦¬ êµ¬ì¡°:
    dt={regday}/product_cls=01/country=all/category=.../item=.../kind=.../product_rank=.../data.json

    Args:
        response_json (dict): API ì‘ë‹µ JSON
        base_prefix (str): ê¸°ë³¸ S3 prefix

    Returns:
        str: S3 ì˜¤ë¸Œì íŠ¸ í‚¤

    Raises:
        ValueError: response_jsonì— condition í•„ë“œê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš°
    """
    try:
        condition = response_json["condition"][0]
    except (KeyError, IndexError, TypeError) as err:
        raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ API ì‘ë‹µ: condition ì—†ìŒ") from err

    return (
        f"{base_prefix}/"
        f"dt={condition['p_regday']}/"
        f"product_cls=01/"
        f"country=all/"
        f"category={condition['p_itemcategorycode']}/"
        f"item={condition['p_itemcode']}/"
        f"kind={condition['p_kindcode']}/"
        f"product_rank={condition['p_productrankcode']}/"
        f"data.json"
    )


# ============================================================
# 3. API í˜¸ì¶œ í•¨ìˆ˜
# ============================================================


def fetch_eco_data(
    base_url: str,
    params: dict[str, Any],
    *,
    timeout: int = 10,
    max_retries: int = 3,
    retry_delay: float = 3.0,  # 3ì´ˆ
) -> dict[str, Any]:
    """
    ì¹œí™˜ê²½ ê°€ê²© APIì—ì„œ ë°ì´í„°ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

    Args:
        base_url (str): API ì—”ë“œí¬ì¸íŠ¸
        params (dict): ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
        timeout (int): ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        retry_delay (float): ì¬ì‹œë„ ê°„ê²© (ì´ˆ)

    Returns:
        dict: API ì‘ë‹µ JSON

    Raises:
        requests.RequestException: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´í›„ì—ë„ HTTP ìš”ì²­ì´ ì‹¤íŒ¨í•œ ê²½ìš°
        ValueError: ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í•˜ê±°ë‚˜ ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
    """
    for attempt in range(max_retries):
        try:
            response = requests.get(base_url, params=params, timeout=timeout)
            response.raise_for_status()
            return response.json()
        except (requests.RequestException, ValueError) as e:
            logging.warning(f"API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
            time.sleep(retry_delay)


# ============================================================
# 4. API í˜¸ì¶œ ë° ì ì¬
# ============================================================


def collect_eco_data(
    base_url: str,
    regday: str,
    common_params: dict[str, Any],
    bucket: str,
    eco_params_file: str = "plugins/eco_api_params.json",
) -> None:
    """
    ì¹œí™˜ê²½ ê°€ê²© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  S3ì— ì›ë³¸ API ì‘ë‹µì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    S3 ê²½ë¡œëŠ” ìš”ì²­í•œ regdayê°€ ì•„ë‹ˆë¼ API ì‘ë‹µì— í¬í•¨ëœ regday ê¸°ì¤€ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤.
    eco_api_params.json íŒŒì¼ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•©ë‹ˆë‹¤.
    overwrite/new ì—¬ë¶€ë¥¼ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.

    Args:
        base_url (str): API ì—”ë“œí¬ì¸íŠ¸
        regday (str): ìš”ì²­í•  regday (YYYY-MM-DD)
        common_params (dict): ê³µí†µ API íŒŒë¼ë¯¸í„°
        bucket (str): ëŒ€ìƒ S3 ë²„í‚· ì´ë¦„
        eco_params_file (str): eco API íŒŒë¼ë¯¸í„° JSON íŒŒì¼ ê²½ë¡œ
    """
    # JSON íŒŒì¼ì—ì„œ eco_api_params ë¶ˆëŸ¬ì˜¤ê¸°
    eco_params_path = Path(eco_params_file)
    with eco_params_path.open("r", encoding="utf-8") as f:
        eco_api_params = json.load(f)

    overwrite_count = 0
    new_count = 0

    for params in eco_api_params:
        params_with_regday = {
            **common_params,
            **params,
            "p_regday": regday,
        }

        response_json = fetch_eco_data(
            base_url=base_url,
            params=params_with_regday,
        )

        object_key = build_s3_object_key(response_json)

        existed = upload_json_to_s3(
            data=response_json,
            bucket=bucket,
            key=object_key,
        )

        if existed:
            overwrite_count += 1
            logger.info(f"â™»ï¸ overwrite: s3://{bucket}/{object_key}")
        else:
            new_count += 1
            logger.info(f"ğŸ†• new: s3://{bucket}/{object_key}")

    logger.info(f"Summary for regday={regday}: new={new_count}, overwrite={overwrite_count}")
